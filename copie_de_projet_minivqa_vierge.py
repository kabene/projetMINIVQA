# -*- coding: utf-8 -*-
"""Copie de Projet_miniVQA_vierge.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nsyAuV8rfze8qMA8JnevsI4ehnbHqG-Y

Projet :

Vous devez créer un pipeline d'apprentissage automatique, basé sur les réseau de neurones, sur la tâche Visual Question Answering (VQA). Ceci comprend:*
- Creation d'un modèle
- Creation d'un dataloader
- Entraînement selon les splits
- Test sur le split de test
- Ecriture d'un rapport Scientifique

**Creation d'un modèle**

Les images sont de tailles 124x124. Les modèles classiques proposés par pytorch prennent en entrée des images de taille 224x224. <br/>
Nous voulons un modèle qui prennent en entrée les images de tailles 112x112.

Ce modèle encode l'image avec un CNN, et intègre la question dans le pipeline.

**Creation d'un dataloader**
  - sentence embedding (lente forward pass, il est judicieux de calculer cette représentation que une fois sachant que le modèle est pré-entrainé (et fixé).
  - il faut passer d'image 124x124 en 112x112, ceci permet de faire de la data-augementation (randomresizecrop, randomflip, ...)
  - Le data loader retourne, au moins, la question, l'image et le label

**Entraînement selon les splits**

Il faut créer une procédure d'entrainement et selectionner votre meilleur modèle. Vous aurez surement besoin des methodes torch.save et torch.load pour gérer la sauvegarde de vos modèles.

Il y a plein de manières d'améliorer votre entrainement, voici quelques pistes :
  - crop dataloader (image augmentation)
  - dropout
  - Model ensembling
  - Lr scheduler
  - Early stop

Pour plus de facilités, vous pouvez directement connecter votre google drive a votre colab.
https://colab.research.google.com/notebooks/io.ipynb

 **Pas permis:**<br/>
 - Scale l'image en 224x224 et utiliser un réseau préentrainé


**Ne pas oublier**
- net.train(), net.eval() ne calcule pas les gradients et le dropout

**PS:**
Utiliser adam optimizer comme pour la scéance CNN.

**Test sur le split de test**:
Pour la compétition, il faut reporter la réponse choisie par le modèle (argmax) (cf sample_submission.csv).<br/>
Pour le rapport, il faut reporter l'accuracy top-1 (donnée par le argmax, i.e. cette réponse est elle la bonne réponse) et l'accuracy top-5 (la bonne réponse se trouve-elle dans les 5 plus grandes confiances données par votre modèle? )

**Ecriture d'un rapport Scientifique**

Au minimum, expliquer les points ci-dessus.

**Cela *peut* comprendre**:
- Explorez le jeu de données, donnez des exemples pour quelques classes, la distribution des labels (sous forme de graph ?)
- Quand vous prenez une decision (par exemple, data augementation), montrez visuellement l'effet de cette décision
- Expliquez votre réseau, que sont des convolution et du pooling, mettez des figures, expliquez votre stratégie pour définir la taille des filtres, etc..
- Montrez l'évolution de vos résultats par epoch (sous forme de graph ?), plottez l'accuracy, et la loss. Quelle stratégie d'apprentissage utilisez vous (lr scheduler, early stop, ...)
- Si vous utilisez du dropout, model ensembling, autre technique : explication et effet de cette technique, ...
- **PS: on a surement pas le temps de tout faire ! Concentrez vous sur certains points, et montrez leur impact (qu'il soit négatif ou positif, c'est ca la science...)**
"""

!file=1pfd5-i_F20zViKIYwbQ8jL1p78s_E6uX && wget --load-cookies /tmp/cookies.txt "https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id='${file} -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\1\n/p')&id="${file} -O images.zip && rm -rf /tmp/cookies.txt \
&& unzip -qq images.zip && \
git clone https://github.com/jbdel/miniVQA

!ls && ls -d miniVQA/*

!ls miniVQA/train.csv

"""## **Overview dataset**"""

!wc -l miniVQA/*.csv

import json
import random
import matplotlib.pyplot as plt
import cv2

image_question = json.load(open('miniVQA/image_question.json'))
plt.figure(figsize=([30, 20]))

for i in range(5):
  plt.subplot(1, 5, i+1)
  random_image = random.choice(list(image_question.keys()))
  _, random_question = random.choice(image_question[random_image])
  plt.imshow(cv2.resize(cv2.imread('image124/'+random_image+'.jpg'), (124,124)))
  plt.xlabel('image_id: '+random_image)
  plt.title(random_question)

"""## **Sentence Embedding**"""

!pip install sentence_transformers

from sentence_transformers import SentenceTransformer
import time

model = SentenceTransformer('distilbert-base-nli-mean-tokens').cuda() # ne pas toucher

sentences = 'This framework generates embeddings for each input sentence word hello ok'
time_start = time.time()
sentence_embeddings = model.encode(sentences)
print(time.time()-time_start)
print(sentence_embeddings.shape)

#IMPORTS
import pandas as pd
import csv
import pprint
import glob
import os
import torch
import torch.nn as nn
from PIL import Image
from torchvision.transforms import *
import numpy as np
import torch.optim as optim
import json
import random
import matplotlib.pyplot as plt
import cv2
import toolz
import heapq
from sentence_transformers import SentenceTransformer

#label list
labels={}
txt_file = open("miniVQA/answer_list.txt")
i=0
for line in txt_file:
  line=line.rstrip("\n")
  labels[i]=line
  i=i+1
#pprint.pprint(labels)

#model
model=SentenceTransformer('distilbert-base-nli-mean-tokens').cuda()

#DataLoader
class Dataset(torch.utils.data.Dataset):
  def __init__(self, split):
    assert split in  ["train", "val","test"]
    self.dataframe=pd.read_csv('miniVQA/'+split+'.csv')
    if split=="train" :
      self.transform = transforms.Compose([
          transforms.RandomResizedCrop(112),
          transforms.RandomHorizontalFlip(),
          transforms.ToTensor(),
      ])
    elif split =="val"or split=="test":
      self.transform = transforms.Compose([
          transforms.Resize((112,112)),
          transforms.ToTensor(),
      ])
    with open('miniVQA/image_question.json') as json_file: 
      self.questions = json.load(json_file)
    self.questionsTransformed={}
    for i in self.questions:
      for q in self.questions[i]:
        self.questionsTransformed[q[0]]=torch.Tensor(model.encode(q[1]))
  def __len__(self):
    return len(self.dataframe.index)
     
  def __getitem__(self, index):
    question_id=self.dataframe.id[index]
    questionTransformed= self.questionsTransformed[question_id]
    image=str(question_id)[:-3]
    img = Image.open('image124/'+image+'.jpg').convert('RGB')
    img = self.transform(img)
    label=self.dataframe.label[index]
    return question_id,questionTransformed,img,label

train_dataset = Dataset(split="train")
print("Nombre questions pour test", len(train_dataset))
train_generator = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)

val_dataset = Dataset(split="val")
print("Nombre questions pour val", len(val_dataset))
val_generator = torch.utils.data.DataLoader(val_dataset, batch_size=64, shuffle=True)

test_dataset=Dataset(split="test")
print("Nbr questions pour test",len(test_dataset))
test_generator = torch.utils.data.DataLoader(test_dataset,batch_size=1, shuffle=False)

class Network(nn.Module): 
    def __init__(self, num_classes=None):
        super(Network, self).__init__()
       
        self.features = nn.Sequential(nn.Conv2d( 
            in_channels=3,out_channels=64,kernel_size=11,stride=4,padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2),
            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=5,stride=1,padding=2),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2),
            nn.Conv2d(in_channels=192,out_channels=384,kernel_size=3,stride=1,padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=384,out_channels=256,kernel_size=3,stride=1,padding=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,stride=1,padding=1),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(kernel_size=3,stride=2)
            )
        self.classifier = nn.Sequential(
             nn.Linear(1024 +768,512),
             nn.Linear(512,num_classes),
        )


    def forward(self, x: torch.Tensor, question: torch.Tensor):
        x = self.features(x)
        x = torch.flatten(x,1)
        x = torch.cat([x,question],1)
        # x = nn.Dropout(x,p=0.2)
        x = self.classifier(x)
        return x

#parametres -------------------------------------
learning_rate=1e-4
batch_size=32
num_epochs=125 
#optimisation-----------------------------------------------
loss_func = torch.nn.CrossEntropyLoss()
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

def train(net, batch_size, learning_rate, num_epochs,optimizer,loss_func):
    loss_table=[]
    val_accuracy=[]
    for i in range(num_epochs):
     # scheduler.step()  scheduler mais diminue accuracy
      loss_epoch=[]
      net.train()
      for j, sample in enumerate(train_generator):
        question_id,questionTransformed,img,y = sample
        x = img
        optimizer.zero_grad()
        out = net(x.cuda(), questionTransformed.cuda())
        loss = loss_func(out, y.cuda())
        loss.backward()
        loss_epoch.append(loss.item())
        optimizer.step()
        print('\r Epoch', i, 'Step', j , ':' , str(loss.data.cpu().numpy()), end="")
      net.eval()
      loss_table.append(np.mean(loss_epoch))
      accuracy = []
      best=0
      for j, sample in enumerate(val_generator):
        question_id,questionTransformed,img,label = sample
        out = net(img.cuda(),questionTransformed.cuda())
        best = np.argmax(out.data.cpu().numpy(), axis=-1)
        accuracy.extend(list(best == label.data.cpu().numpy()))
      print('\n val Accuracy is ' , str(np.mean(accuracy)*100))
      val_accuracy.append(np.mean(accuracy)*100)
    print("val done")
    print("to test")
    soumission(net)
    print('plot training loss:',loss_table )
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.plot(loss_table,'b', label='training loss')
    plt.show()
    print('plot val accuracy:',val_accuracy )
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.plot (val_accuracy,'g',label='val accuracy')
    plt.show()

def soumission(net):
  submission = []
  fields = ['id', 'label']
  for j, sample in enumerate(test_generator):
      question_id,questionTransformed,img,label = sample
      out = net(img.cuda(),questionTransformed.cuda())
      best = np.argmax(out.data.cpu().numpy(), axis=1)
      row = [int(question_id.data.cpu().numpy()[0]), best[0]]
      submission.append(row)
  filename = "submission.csv"
  with open(filename, 'w') as csvfile: 
    csvwriter = csv.writer(csvfile) 
    csvwriter.writerow(fields) 
    csvwriter.writerows(submission)

def isthegood(questionid,best):
  bonnereponse=test_dataset.dataframe.get(questionid)
  return best==bonnereponse

def isInTop5(label,out):
  for val in out.data.cpu().numpy():
    if val == label:
      return true
  return false

def save (net,num_epochs,path,loss,optimizer):
  torch.save({
            'epoch': num_epochs,
            'model_state_dict': net.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            }, path)

def load(path):
  checkpoint = torch.load(path)
  model=Network()
  model.load_state_dict(checkpoint['model_state_dict'])
  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
  epoch = checkpoint['epoch']
  loss = checkpoint['loss']
  model.train()
  #or
  #model.eval()

import torchvision.models as models
path='./result.csv'
net=Network(len(labels)).cuda()
optimizer = optim.Adam(net.parameters(), lr=learning_rate)
train(net, batch_size, learning_rate, num_epochs,optimizer,loss_func)

#net = models.resnet152(pretrained=False)
#in_features = net.fc.in_features
#print(in_features)
#net.fc =nn.Linear(in_features,100)
#train(net.cuda(), num_epochs=1)